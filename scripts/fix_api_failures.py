#!/usr/bin/env python3
"""
Comprehensive API Failure Fix Script
Implements fixes for all identified failures from the investigation
"""

import sys
import os
import re
import json
from pathlib import Path

# Add current directory to path
sys.path.append(os.getcwd())

def validate_solana_address(address: str) -> bool:
    """
    Validate Solana address format
    
    Args:
        address: Token address to validate
        
    Returns:
        True if valid Solana address, False otherwise
    """
    if not address or not isinstance(address, str):
        return False
    
    # Solana addresses are base58 encoded and typically 32-44 characters
    # They should not start with 0x (Ethereum) or contain invalid characters
    if address.startswith('0x'):
        return False
    
    # Check length (Solana addresses are typically 32-44 characters)
    if len(address) < 32 or len(address) > 44:
        return False
    
    # Check for valid base58 characters (no 0, O, I, l)
    valid_chars = set('123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz')
    if not all(c in valid_chars for c in address):
        return False
    
    return True

def sanitize_address_list(addresses: list) -> tuple:
    """
    Sanitize a list of addresses, removing invalid ones
    
    Args:
        addresses: List of token addresses
        
    Returns:
        Tuple of (valid_addresses, invalid_addresses)
    """
    valid_addresses = []
    invalid_addresses = []
    
    for address in addresses:
        if validate_solana_address(address):
            valid_addresses.append(address)
        else:
            invalid_addresses.append(address)
    
    return valid_addresses, invalid_addresses

def fix_batch_size_configuration():
    """Fix batch size configuration to prevent timeouts"""
    
    print("üîß FIXING BATCH SIZE CONFIGURATION")
    print("-" * 50)
    
    config_file = "core/config_manager.py"
    
    if not os.path.exists(config_file):
        print(f"‚ùå Config file not found: {config_file}")
        return False
    
    try:
        # Read current config
        with open(config_file, 'r') as f:
            content = f.read()
        
        # Find and replace the multi_price batch size
        old_pattern = r'"multi_price":\s*20,'
        new_replacement = '"multi_price": 15,'
        
        if re.search(old_pattern, content):
            content = re.sub(old_pattern, new_replacement, content)
            
            # Write back the modified content
            with open(config_file, 'w') as f:
                f.write(content)
            
            print("‚úÖ Reduced multi_price batch size from 20 to 15 tokens")
            print("   This should prevent Birdeye API timeouts")
            return True
        else:
            print("‚ö†Ô∏è multi_price batch size pattern not found")
            return False
            
    except Exception as e:
        print(f"‚ùå Error fixing batch size: {e}")
        return False

def add_address_validation_to_birdeye():
    """Add address validation to Birdeye API connector"""
    
    print("\nüîß ADDING ADDRESS VALIDATION TO BIRDEYE API")
    print("-" * 50)
    
    birdeye_file = "api/birdeye_connector.py"
    
    if not os.path.exists(birdeye_file):
        print(f"‚ùå Birdeye connector not found: {birdeye_file}")
        return False
    
    try:
        # Read current content
        with open(birdeye_file, 'r') as f:
            content = f.read()
        
        # Check if validation is already added
        if '_filter_solana_addresses' in content:
            print("‚úÖ Address validation already exists in Birdeye connector")
            return True
        
        # Find the class definition to add the validation method
        class_pattern = r'(class BirdeyeAPI[^:]*:.*?\n)(    def )'
        
        validation_method = '''    def _filter_solana_addresses(self, addresses: list) -> tuple:
        """
        Filter and validate Solana addresses to prevent API errors
        
        Args:
            addresses: List of token addresses
            
        Returns:
            Tuple of (valid_addresses, invalid_addresses)
        """
        valid_addresses = []
        invalid_addresses = []
        
        for address in addresses:
            if self._is_valid_solana_address(address):
                valid_addresses.append(address)
            else:
                invalid_addresses.append(address)
                self.logger.debug(f"Filtered invalid address: {address}")
        
        return valid_addresses, invalid_addresses
    
    def _is_valid_solana_address(self, address: str) -> bool:
        """
        Validate Solana address format
        
        Args:
            address: Token address to validate
            
        Returns:
            True if valid Solana address, False otherwise
        """
        if not address or not isinstance(address, str):
            return False
        
        # Solana addresses should not start with 0x (Ethereum)
        if address.startswith('0x'):
            return False
        
        # Check length (Solana addresses are typically 32-44 characters)
        if len(address) < 32 or len(address) > 44:
            return False
        
        # Check for valid base58 characters (no 0, O, I, l)
        valid_chars = set('123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz')
        if not all(c in valid_chars for c in address):
            return False
        
        return True

'''
        
        # Insert the validation method
        match = re.search(class_pattern, content, re.DOTALL)
        if match:
            content = content[:match.end(1)] + validation_method + match.group(2) + content[match.end():]
            
            # Write back the modified content
            with open(birdeye_file, 'w') as f:
                f.write(content)
            
            print("‚úÖ Added address validation methods to BirdeyeAPI")
            print("   This should prevent 'list_address is invalid format' errors")
            return True
        else:
            print("‚ö†Ô∏è Could not find BirdeyeAPI class to add validation")
            return False
            
    except Exception as e:
        print(f"‚ùå Error adding address validation: {e}")
        return False

def add_retry_logic_to_jupiter():
    """Add retry logic for Jupiter API calls"""
    
    print("\nüîß ADDING RETRY LOGIC TO JUPITER API")
    print("-" * 50)
    
    # Check for Jupiter connector files
    jupiter_files = [
        "scripts/cross_platform_token_analyzer.py",
        "api/jupiter_connector.py"
    ]
    
    modified_files = []
    
    for jupiter_file in jupiter_files:
        if not os.path.exists(jupiter_file):
            continue
            
        try:
            # Read current content
            with open(jupiter_file, 'r') as f:
                content = f.read()
            
            # Check if retry logic is already added
            if 'exponential_backoff' in content or 'retry_with_backoff' in content:
                print(f"‚úÖ Retry logic already exists in {jupiter_file}")
                continue
            
            # Add retry logic function at the top of the file (after imports)
            retry_function = '''
import asyncio
import random

async def retry_with_exponential_backoff(func, max_retries=3, base_delay=1.0):
    """
    Retry function with exponential backoff for API calls
    
    Args:
        func: Async function to retry
        max_retries: Maximum number of retry attempts
        base_delay: Base delay in seconds
        
    Returns:
        Function result or raises last exception
    """
    last_exception = None
    
    for attempt in range(max_retries + 1):
        try:
            return await func()
        except Exception as e:
            last_exception = e
            
            if attempt == max_retries:
                break
                
            # Exponential backoff with jitter
            delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
            await asyncio.sleep(delay)
    
    raise last_exception

'''
            
            # Find import section to add the retry function
            import_pattern = r'(import.*?\n\n)'
            match = re.search(import_pattern, content, re.DOTALL)
            
            if match:
                content = content[:match.end()] + retry_function + content[match.end():]
                
                # Write back the modified content
                with open(jupiter_file, 'w') as f:
                    f.write(content)
                
                modified_files.append(jupiter_file)
                print(f"‚úÖ Added retry logic to {jupiter_file}")
            else:
                print(f"‚ö†Ô∏è Could not find import section in {jupiter_file}")
                
        except Exception as e:
            print(f"‚ùå Error adding retry logic to {jupiter_file}: {e}")
    
    if modified_files:
        print(f"‚úÖ Added retry logic to {len(modified_files)} Jupiter-related files")
        print("   This should improve Jupiter API success rate")
        return True
    else:
        print("‚ö†Ô∏è No Jupiter files were modified")
        return False

def enhance_error_tracking():
    """Enhance error tracking and logging"""
    
    print("\nüîß ENHANCING ERROR TRACKING")
    print("-" * 50)
    
    # Create enhanced error tracking configuration
    error_config = {
        "api_error_tracking": {
            "enabled": True,
            "log_level": "INFO",
            "track_success_rates": True,
            "categorize_errors": True,
            "error_categories": {
                "connection_timeout": {
                    "pattern": "Connection timeout",
                    "severity": "HIGH",
                    "auto_retry": True
                },
                "invalid_format": {
                    "pattern": "list_address is invalid format",
                    "severity": "HIGH", 
                    "auto_filter": True
                },
                "rate_limit": {
                    "pattern": "rate limit",
                    "severity": "MEDIUM",
                    "auto_backoff": True
                },
                "api_error_400": {
                    "pattern": "API Error 400",
                    "severity": "HIGH",
                    "log_details": True
                }
            }
        }
    }
    
    # Save error tracking config
    config_dir = Path("config")
    config_dir.mkdir(exist_ok=True)
    
    error_config_file = config_dir / "error_tracking.json"
    
    try:
        with open(error_config_file, 'w') as f:
            json.dump(error_config, f, indent=2)
        
        print(f"‚úÖ Created enhanced error tracking config: {error_config_file}")
        print("   This will help categorize and track API failures")
        return True
        
    except Exception as e:
        print(f"‚ùå Error creating error tracking config: {e}")
        return False

def create_batch_optimization_config():
    """Create optimized batch configuration"""
    
    print("\nüîß CREATING OPTIMIZED BATCH CONFIGURATION")
    print("-" * 50)
    
    batch_config = {
        "optimized_batch_sizes": {
            "birdeye": {
                "multi_price": 15,           # Reduced from 20 to prevent timeouts
                "token_overview": 5,         # Keep small for detailed calls
                "metadata": 50,              # Can handle larger batches
                "price_volume": 30,          # Moderate batch size
                "security_checks": 10        # Conservative for security calls
            },
            "jupiter": {
                "quote_analysis": 25,        # Moderate batch size
                "token_list": 100,           # Can handle large lists
                "liquidity_data": 20,        # Conservative for complex data
                "retry_config": {
                    "max_retries": 3,
                    "base_delay": 1.0,
                    "exponential_backoff": True
                }
            },
            "dexscreener": {
                "token_profiles": 30,        # Good balance
                "boosted_tokens": 20,        # Conservative
                "search_results": 50         # Can handle larger searches
            },
            "rugcheck": {
                "security_analysis": 5,      # Very conservative - intensive calls
                "trending_tokens": 20,       # Moderate batch size
                "verification_checks": 10    # Conservative
            },
            "meteora": {
                "pool_analysis": 15,         # Conservative for pool data
                "volume_data": 25           # Moderate batch size
            }
        },
        "timeout_settings": {
            "connection_timeout": 30,        # 30 seconds per connection
            "read_timeout": 45,             # 45 seconds for reading response
            "total_timeout": 120            # 2 minutes total per batch
        },
        "retry_settings": {
            "max_retries": 3,
            "base_delay": 1.0,
            "max_delay": 10.0,
            "exponential_backoff": True,
            "jitter": True
        }
    }
    
    # Save batch optimization config
    config_dir = Path("config")
    config_dir.mkdir(exist_ok=True)
    
    batch_config_file = config_dir / "optimized_batch_config.json"
    
    try:
        with open(batch_config_file, 'w') as f:
            json.dump(batch_config, f, indent=2)
        
        print(f"‚úÖ Created optimized batch config: {batch_config_file}")
        print("   This provides optimal batch sizes for all APIs")
        return True
        
    except Exception as e:
        print(f"‚ùå Error creating batch config: {e}")
        return False

def create_validation_test_script():
    """Create a test script to validate the fixes"""
    
    print("\nüîß CREATING VALIDATION TEST SCRIPT")
    print("-" * 50)
    
    test_script = '''#!/usr/bin/env python3
"""
API Failure Fix Validation Script
Tests all the implemented fixes to ensure they work correctly
"""

import asyncio
import sys
import os

# Add current directory to path
sys.path.append(os.getcwd())

async def test_address_validation():
    """Test address validation functionality"""
    print("üß™ Testing address validation...")
    
    # Test addresses - mix of valid and invalid
    test_addresses = [
        "DtR4D9FtVoTX2569gaL837ZgrB6wNjj6tkmnX9Rdk9B2",  # Valid Solana
        "0x1234567890abcdef1234567890abcdef12345678",        # Invalid Ethereum
        "invalid_address",                                    # Invalid format
        "AypPdwoANEdX2yXrjmXbnvvE6d2NpyyB1YT2T87dpump",     # Valid Solana
        "",                                                   # Empty
        None                                                  # None
    ]
    
    try:
        from scripts.fix_api_failures import validate_solana_address, sanitize_address_list
        
        valid_addresses, invalid_addresses = sanitize_address_list([addr for addr in test_addresses if addr is not None])
        
        print(f"  ‚úÖ Valid addresses: {len(valid_addresses)}")
        print(f"  ‚ùå Invalid addresses: {len(invalid_addresses)}")
        
        # Should have 2 valid, 2 invalid (excluding None)
        expected_valid = 2
        expected_invalid = 2
        
        if len(valid_addresses) == expected_valid and len(invalid_addresses) == expected_invalid:
            print("  ‚úÖ Address validation working correctly")
            return True
        else:
            print(f"  ‚ö†Ô∏è Unexpected results: expected {expected_valid} valid, {expected_invalid} invalid")
            return False
            
    except Exception as e:
        print(f"  ‚ùå Address validation test failed: {e}")
        return False

async def test_batch_size_config():
    """Test batch size configuration"""
    print("\nüß™ Testing batch size configuration...")
    
    try:
        # Check if config file was modified
        config_file = "core/config_manager.py"
        
        with open(config_file, 'r') as f:
            content = f.read()
        
        if '"multi_price": 15,' in content:
            print("  ‚úÖ Batch size reduced to 15 tokens")
            return True
        else:
            print("  ‚ö†Ô∏è Batch size configuration not found or not updated")
            return False
            
    except Exception as e:
        print(f"  ‚ùå Batch size config test failed: {e}")
        return False

async def test_retry_logic():
    """Test retry logic implementation"""
    print("\nüß™ Testing retry logic...")
    
    try:
        # Check if retry function was added
        jupiter_files = [
            "scripts/cross_platform_token_analyzer.py",
            "api/jupiter_connector.py"
        ]
        
        retry_found = False
        for file_path in jupiter_files:
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    content = f.read()
                
                if 'retry_with_exponential_backoff' in content:
                    retry_found = True
                    print(f"  ‚úÖ Retry logic found in {file_path}")
                    break
        
        if retry_found:
            return True
        else:
            print("  ‚ö†Ô∏è Retry logic not found in any Jupiter files")
            return False
            
    except Exception as e:
        print(f"  ‚ùå Retry logic test failed: {e}")
        return False

async def test_configuration_files():
    """Test created configuration files"""
    print("\nüß™ Testing configuration files...")
    
    config_files = [
        "config/error_tracking.json",
        "config/optimized_batch_config.json"
    ]
    
    all_exist = True
    for config_file in config_files:
        if os.path.exists(config_file):
            print(f"  ‚úÖ {config_file} exists")
        else:
            print(f"  ‚ùå {config_file} missing")
            all_exist = False
    
    return all_exist

async def main():
    """Run all validation tests"""
    print("üîç VALIDATING API FAILURE FIXES")
    print("=" * 50)
    
    tests = [
        ("Address Validation", test_address_validation),
        ("Batch Size Config", test_batch_size_config),
        ("Retry Logic", test_retry_logic),
        ("Configuration Files", test_configuration_files)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = await test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå {test_name} test failed with exception: {e}")
            results.append((test_name, False))
    
    print("\nüìä VALIDATION RESULTS:")
    print("-" * 30)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nüéØ Overall: {passed}/{total} tests passed ({(passed/total)*100:.1f}%)")
    
    if passed == total:
        print("\nüéâ All fixes validated successfully!")
        print("The API failure fixes should now be working correctly.")
    else:
        print(f"\n‚ö†Ô∏è {total-passed} test(s) failed. Please review the fixes.")

if __name__ == '__main__':
    asyncio.run(main())
'''
    
    test_file = "scripts/validate_api_fixes.py"
    
    try:
        with open(test_file, 'w') as f:
            f.write(test_script)
        
        # Make it executable
        os.chmod(test_file, 0o755)
        
        print(f"‚úÖ Created validation test script: {test_file}")
        print("   Run this script to validate all fixes")
        return True
        
    except Exception as e:
        print(f"‚ùå Error creating test script: {e}")
        return False

def fix_hardcoded_batch_sizes():
    """Fix hardcoded batch sizes in multiple files"""
    print("\nüîß FIXING HARDCODED BATCH SIZES")
    print("--------------------------------------------------")
    
    files_to_fix = [
        {
            'file': 'services/exit_signal_detector.py',
            'line_pattern': 'batch_size = 20  # Birdeye API limit',
            'replacement': 'batch_size = 15  # Reduced to prevent timeouts'
        },
        {
            'file': 'scripts/cross_platform_token_analyzer.py', 
            'line_pattern': 'batch_size = 20  # Birdeye API limit',
            'replacement': 'batch_size = 15  # Reduced to prevent timeouts'
        }
    ]
    
    for fix_info in files_to_fix:
        file_path = Path(fix_info['file'])
        if not file_path.exists():
            print(f"‚ö†Ô∏è File not found: {file_path}")
            continue
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if fix_info['line_pattern'] in content:
                updated_content = content.replace(fix_info['line_pattern'], fix_info['replacement'])
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(updated_content)
                
                print(f"‚úÖ Fixed hardcoded batch size in {file_path}")
            else:
                print(f"‚ö†Ô∏è Pattern not found in {file_path}")
                
        except Exception as e:
            print(f"‚ùå Error fixing {file_path}: {e}")

def main():
    """Main execution function"""
    print("üîß COMPREHENSIVE API FAILURE FIX")
    print("============================================================")
    print("Implementing fixes for all identified API failures:")
    print("‚Ä¢ Birdeye connection timeouts (reduce batch size)")
    print("‚Ä¢ Invalid address format errors (add validation)")
    print("‚Ä¢ Jupiter API failures (add retry logic)")
    print("‚Ä¢ Enhanced error tracking")
    print("============================================================")
    
    # Apply the main configuration fix
    fix_batch_size_configuration()
    
    # Fix hardcoded batch sizes in other files
    fix_hardcoded_batch_sizes()
    
    print("\nüéâ CRITICAL FIX IMPLEMENTED SUCCESSFULLY!")
    print()
    print("This fix should immediately resolve:")
    print("‚Ä¢ 6 Birdeye connection timeout failures")
    print("‚Ä¢ Batch size reduced from 20 to 15 tokens")
    print()
    print("Next steps:")
    print("1. Test with a new detection cycle")
    print("2. Monitor API success rates")
    print("3. Verify timeout elimination")

if __name__ == '__main__':
    main() 