#!/usr/bin/env python3
"""
ğŸš€ COMPLETE ANALYSIS TEST - Enhanced Data Fetcher Demo
Tests the fixed API data pipeline with full token analysis

This test demonstrates:
1. Enhanced data fetcher working correctly
2. Real trading data flowing through to scoring
3. Complete analysis pipeline with all metrics
4. Performance comparison vs legacy methods
"""

import asyncio
import sys
import os
import time
import json
from datetime import datetime

# Add project root to Python path
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, 'scripts'))

from enhanced_data_fetcher import EnhancedDataFetcher
try:
    from early_gem_detector import EarlyGemDetector
except ImportError:
    from src.detectors.early_gem_detector import EarlyGemDetector
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('CompleteAnalysisTest')

# Test token address
TEST_TOKEN = "tk28Q41zkgtAkfuN86JXfpD8wFrdq5WxUC4yGCBpump"

def print_header(title: str):
    """Print a formatted header"""
    print("\n" + "=" * 80)
    print(f"ğŸš€ {title}")
    print("=" * 80)

def print_section(title: str):
    """Print a formatted section header"""
    print(f"\nğŸ“‹ {title}")
    print("-" * 60)

def format_currency(value: float) -> str:
    """Format currency values"""
    if value >= 1000000:
        return f"${value/1000000:.2f}M"
    elif value >= 1000:
        return f"${value/1000:.1f}K"
    else:
        return f"${value:.2f}"

def format_percentage(value: float) -> str:
    """Format percentage values"""
    return f"{value:.2f}%" if value else "0.00%"

async def test_enhanced_data_fetcher():
    """Test the enhanced data fetcher directly"""
    print_header("ENHANCED DATA FETCHER TEST")
    
    try:
        fetcher = EnhancedDataFetcher(logger)
        
        print(f"ğŸ¯ Testing token: {TEST_TOKEN}")
        print(f"â° Starting at: {datetime.now().strftime('%H:%M:%S')}")
        
        start_time = time.time()
        enhanced_data = await fetcher.enhance_token_with_comprehensive_data(TEST_TOKEN)
        fetch_time = time.time() - start_time
        
        print(f"âš¡ Fetch completed in: {fetch_time:.2f} seconds")
        print()
        
        if enhanced_data.get('error'):
            print(f"âŒ Error: {enhanced_data['error']}")
            return None
        
        # Display comprehensive results
        print_section("BASIC TOKEN INFO")
        print(f"ğŸ“› Symbol: {enhanced_data.get('symbol', 'Unknown')}")
        print(f"ğŸ“ Name: {enhanced_data.get('name', 'Unknown')}")
        print(f"ğŸ’° Price: ${enhanced_data.get('price_usd', 0):.8f}")
        print(f"ğŸ“Š Market Cap: {format_currency(enhanced_data.get('market_cap', 0))}")
        print(f"ğŸ’§ Liquidity: {format_currency(enhanced_data.get('liquidity_usd', 0))}")
        
        print_section("TRADING ACTIVITY")
        print(f"ğŸ“ˆ Volume 24h: {format_currency(enhanced_data.get('volume_24h', 0))}")
        print(f"ğŸ“ˆ Volume 6h: {format_currency(enhanced_data.get('volume_6h', 0))}")
        print(f"ğŸ“ˆ Volume 1h: {format_currency(enhanced_data.get('volume_1h', 0))}")
        print(f"ğŸ”„ Trades 24h: {enhanced_data.get('trades_24h', 0):,}")
        print(f"ğŸ”„ Trades 1h: {enhanced_data.get('trades_1h', 0):,}")
        print(f"ğŸ‘¥ Unique Traders 24h: {enhanced_data.get('unique_traders_24h', 0)}")
        
        print_section("PRICE MOVEMENTS")
        print(f"ğŸ“Š Change 24h: {format_percentage(enhanced_data.get('price_change_24h', 0))}")
        print(f"ğŸ“Š Change 6h: {format_percentage(enhanced_data.get('price_change_6h', 0))}")
        print(f"ğŸ“Š Change 1h: {format_percentage(enhanced_data.get('price_change_1h', 0))}")
        print(f"ğŸ“Š Change 5m: {format_percentage(enhanced_data.get('price_change_5m', 0))}")
        
        print_section("SECURITY & HOLDERS")
        print(f"ğŸ›¡ï¸ Is Scam: {'âŒ Yes' if enhanced_data.get('is_scam') else 'âœ… No'}")
        print(f"âš ï¸ Is Risky: {'âš ï¸ Yes' if enhanced_data.get('is_risky') else 'âœ… No'}")
        print(f"ğŸ”’ Security Score: {enhanced_data.get('security_score', 0):.1f}/10")
        print(f"ğŸ‘¥ Holder Count: {enhanced_data.get('holder_count', 0):,}")
        print(f"ğŸ‹ Top Holder %: {format_percentage(enhanced_data.get('top_holder_percentage', 0))}")
        
        print_section("DERIVED METRICS")
        print(f"ğŸ’¹ Volume/MCap Ratio: {enhanced_data.get('volume_mcap_ratio', 0):.4f}")
        print(f"ğŸ’§ Liquidity/MCap Ratio: {enhanced_data.get('liquidity_mcap_ratio', 0):.4f}")
        print(f"ğŸ“Š Buy/Sell Ratio: {enhanced_data.get('buy_sell_ratio', 0):.2f}")
        print(f"ğŸ¯ Trades per Trader: {enhanced_data.get('trades_per_trader', 0):.1f}")
        
        print_section("DATA QUALITY ASSESSMENT")
        quality = enhanced_data.get('data_quality', 'unknown')
        coverage = enhanced_data.get('coverage_score', 0)
        sources = ', '.join(enhanced_data.get('enhancement_sources', []))
        
        quality_emoji = {
            'excellent': 'ğŸŸ¢',
            'good': 'ğŸŸ¡', 
            'poor': 'ğŸŸ ',
            'failed': 'ğŸ”´'
        }.get(quality, 'âšª')
        
        print(f"{quality_emoji} Data Quality: {quality.upper()}")
        print(f"ğŸ“Š Coverage Score: {coverage:.1f}%")
        print(f"ğŸ”— Sources: {sources}")
        
        return enhanced_data
        
    except Exception as e:
        print(f"âŒ Enhanced data fetcher test failed: {e}")
        return None

async def test_full_analysis_pipeline():
    """Test the complete early gem detector analysis pipeline"""
    print_header("FULL ANALYSIS PIPELINE TEST")
    
    try:
        # Initialize detector
        detector = EarlyGemDetector(debug_mode=True)
        
        print(f"ğŸ¯ Analyzing token: {TEST_TOKEN}")
        print(f"â° Starting analysis at: {datetime.now().strftime('%H:%M:%S')}")
        
        # Create candidate token data (simulating discovery from API)
        candidate = {
            'address': TEST_TOKEN,
            'symbol': 'Unknown',  # Will be enhanced
            'source': 'test_analysis',
            'price': 0,  # Will be enhanced
            'marketCap': 0,  # Will be enhanced
            'liquidity': 0,  # Will be enhanced
            'volume': {},  # Empty - will be enhanced
            'volume_24h': 0,  # Zero - will be enhanced
            'trades_24h': 0,  # Zero - will be enhanced
            'unique_traders': 0,  # Zero - will be enhanced
            'discovery_timestamp': time.time()
        }
        
        print_section("BEFORE ENHANCEMENT")
        print(f"ğŸ“› Symbol: {candidate.get('symbol', 'Unknown')}")
        print(f"ğŸ’° Price: ${candidate.get('price', 0)}")
        print(f"ğŸ“Š Market Cap: {format_currency(candidate.get('marketCap', 0))}")
        print(f"ğŸ“ˆ Volume 24h: {format_currency(candidate.get('volume_24h', 0))}")
        print(f"ğŸ”„ Trades 24h: {candidate.get('trades_24h', 0)}")
        print(f"ğŸ‘¥ Unique Traders: {candidate.get('unique_traders', 0)}")
        
        # Run the complete analysis pipeline
        start_time = time.time()
        result = await detector._analyze_single_candidate(candidate)
        analysis_time = time.time() - start_time
        
        print(f"\nâš¡ Analysis completed in: {analysis_time:.2f} seconds")
        
        if not result:
            print("âŒ Analysis returned None - token was filtered out")
            return None
        
        # Extract results
        enriched_candidate = result.get('candidate', {})
        final_score = result.get('final_score', 0)
        scoring_breakdown = result.get('scoring_breakdown', {})
        conviction_level = result.get('conviction_level', 'low')
        enhanced_metrics = result.get('enhanced_metrics', {})
        
        print_section("AFTER ENHANCEMENT & ANALYSIS")
        print(f"ğŸ“› Symbol: {enriched_candidate.get('symbol', 'Unknown')}")
        print(f"ğŸ“ Name: {enriched_candidate.get('name', 'Unknown')}")
        print(f"ğŸ’° Price: ${enriched_candidate.get('price_usd', enriched_candidate.get('price', 0)):.8f}")
        print(f"ğŸ“Š Market Cap: {format_currency(enriched_candidate.get('market_cap', enriched_candidate.get('marketCap', 0)))}")
        print(f"ğŸ’§ Liquidity: {format_currency(enriched_candidate.get('liquidity_usd', enriched_candidate.get('liquidity', 0)))}")
        
        print_section("TRADING DATA (ENHANCED)")
        print(f"ğŸ“ˆ Volume 24h: {format_currency(enriched_candidate.get('volume_24h', 0))}")
        print(f"ğŸ“ˆ Volume 1h: {format_currency(enriched_candidate.get('volume_1h', 0))}")
        print(f"ğŸ”„ Trades 24h: {enriched_candidate.get('trades_24h', 0):,}")
        print(f"ğŸ‘¥ Unique Traders 24h: {enriched_candidate.get('unique_traders_24h', enriched_candidate.get('unique_traders', 0))}")
        print(f"ğŸ’¹ Buy/Sell Ratio: {enriched_candidate.get('buy_sell_ratio', 0):.2f}")
        
        print_section("SCORING RESULTS")
        conviction_emoji = {
            'very_high': 'ğŸ”¥',
            'high': 'ğŸš€', 
            'moderate': 'âš¡',
            'low': 'ğŸ“Š'
        }.get(conviction_level, 'ğŸ“Š')
        
        print(f"{conviction_emoji} Final Score: {final_score:.2f}/100")
        print(f"ğŸ¯ Conviction Level: {conviction_level.upper()}")
        print(f"ğŸ“Š Data Quality: {enriched_candidate.get('data_quality', 'unknown')}")
        print(f"ğŸ”— Enhancement Sources: {', '.join(enriched_candidate.get('enhancement_sources', []))}")
        
        print_section("ENHANCED METRICS")
        print(f"âš¡ Velocity Score: {enhanced_metrics.get('velocity_score', 0):.3f}")
        print(f"ğŸ¯ First 100 Score: {enhanced_metrics.get('first_100_score', 0):.1f}")
        print(f"ğŸ’§ Liquidity Quality: {enhanced_metrics.get('liquidity_quality', 0):.1f}")
        print(f"ğŸ“ Graduation Risk: {enhanced_metrics.get('graduation_risk', 0):.1f}")
        
        # Display scoring breakdown if available
        if scoring_breakdown:
            print_section("DETAILED SCORING BREAKDOWN")
            for category, score in scoring_breakdown.items():
                if isinstance(score, (int, float)):
                    print(f"ğŸ“Š {category.replace('_', ' ').title()}: {score:.2f}")
        
        # Data validation check
        volume_24h = enriched_candidate.get('volume_24h', 0)
        trades_24h = enriched_candidate.get('trades_24h', 0)
        
        print_section("DATA VALIDATION")
        if volume_24h > 0:
            print("âœ… SUCCESS: Volume data successfully enhanced!")
            print(f"   ğŸ“ˆ Volume 24h: {format_currency(volume_24h)}")
        else:
            print("âš ï¸ WARNING: Volume data still zero - may be a new token with no activity")
        
        if trades_24h > 0:
            print("âœ… SUCCESS: Trading activity data successfully enhanced!")
            print(f"   ğŸ”„ Trades 24h: {trades_24h:,}")
        else:
            print("âš ï¸ WARNING: No trading activity detected - may be a very new token")
        
        return result
        
    except Exception as e:
        print(f"âŒ Full analysis pipeline test failed: {e}")
        import traceback
        traceback.print_exc()
        return None
    finally:
        await detector.cleanup()

async def test_performance_comparison():
    """Compare performance of new vs legacy methods"""
    print_header("PERFORMANCE COMPARISON")
    
    try:
        print("ğŸ Testing performance of enhanced data fetcher...")
        
        # Test enhanced fetcher
        fetcher = EnhancedDataFetcher(logger)
        
        print_section("ENHANCED DATA FETCHER")
        start_time = time.time()
        enhanced_data = await fetcher.enhance_token_with_comprehensive_data(TEST_TOKEN)
        enhanced_time = time.time() - start_time
        
        enhanced_coverage = enhanced_data.get('coverage_score', 0)
        enhanced_fields = len([k for k, v in enhanced_data.items() if v not in [None, 0, '', []]])
        
        print(f"âš¡ Time: {enhanced_time:.2f} seconds")
        print(f"ğŸ“Š Coverage: {enhanced_coverage:.1f}%")
        print(f"ğŸ“‹ Fields populated: {enhanced_fields}")
        print(f"ğŸ”— Sources: {', '.join(enhanced_data.get('enhancement_sources', []))}")
        
        # Summary
        print_section("PERFORMANCE SUMMARY")
        print(f"ğŸš€ Enhanced Method: {enhanced_time:.2f}s, {enhanced_coverage:.1f}% coverage")
        print(f"ğŸ¯ Quality: {enhanced_data.get('data_quality', 'unknown')}")
        
        if enhanced_coverage >= 80:
            print("âœ… EXCELLENT: Enhanced method provides comprehensive data coverage!")
        elif enhanced_coverage >= 60:
            print("âœ… GOOD: Enhanced method provides good data coverage")
        else:
            print("âš ï¸ WARNING: Limited data coverage - token may be very new or inactive")
        
    except Exception as e:
        print(f"âŒ Performance comparison failed: {e}")

async def save_test_results(enhanced_data, analysis_result):
    """Save test results to JSON file"""
    try:
        timestamp = int(time.time())
        results = {
            'test_timestamp': timestamp,
            'test_date': datetime.now().isoformat(),
            'test_token': TEST_TOKEN,
            'enhanced_data': enhanced_data,
            'analysis_result': analysis_result,
            'test_metadata': {
                'python_version': sys.version,
                'test_file': __file__,
                'test_success': enhanced_data is not None and analysis_result is not None
            }
        }
        
        filename = f"complete_analysis_test_{timestamp}.json"
        with open(filename, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print_section("TEST RESULTS SAVED")
        print(f"ğŸ“ Results saved to: {filename}")
        print(f"ğŸ“Š File size: {os.path.getsize(filename):,} bytes")
        
    except Exception as e:
        print(f"âš ï¸ Failed to save test results: {e}")

async def main():
    """Run complete analysis test suite"""
    print_header("COMPLETE ANALYSIS TEST SUITE")
    print(f"ğŸ¯ Target Token: {TEST_TOKEN}")
    print(f"â° Test Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”¬ Testing enhanced data pipeline with full analysis")
    
    # Test 1: Enhanced data fetcher
    enhanced_data = await test_enhanced_data_fetcher()
    
    # Test 2: Full analysis pipeline
    analysis_result = await test_full_analysis_pipeline()
    
    # Test 3: Performance comparison
    await test_performance_comparison()
    
    # Save results
    if enhanced_data or analysis_result:
        await save_test_results(enhanced_data, analysis_result)
    
    # Final summary
    print_header("TEST SUITE SUMMARY")
    
    if enhanced_data:
        print("âœ… Enhanced Data Fetcher: SUCCESS")
        print(f"   ğŸ“Š Quality: {enhanced_data.get('data_quality', 'unknown')}")
        print(f"   ğŸ“ˆ Volume 24h: {format_currency(enhanced_data.get('volume_24h', 0))}")
    else:
        print("âŒ Enhanced Data Fetcher: FAILED")
    
    if analysis_result:
        final_score = analysis_result.get('final_score', 0)
        conviction = analysis_result.get('conviction_level', 'low')
        print("âœ… Full Analysis Pipeline: SUCCESS")
        print(f"   ğŸ¯ Final Score: {final_score:.2f}")
        print(f"   ğŸ“Š Conviction: {conviction}")
    else:
        print("âŒ Full Analysis Pipeline: FAILED")
    
    print(f"\nâ° Test Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸš€ Enhanced data pipeline test complete!")

if __name__ == "__main__":
    asyncio.run(main()) 